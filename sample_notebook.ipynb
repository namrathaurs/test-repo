{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sample_notebook.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jul4VkB7iwBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (ONE TIME ONLY) install apex (Ref: https://github.com/NVIDIA/apex/issues/116)\n",
        "%cd ../../\n",
        "!git clone https://www.github.com/nvidia/apex\n",
        "%cd apex\n",
        "!python setup.py install\n",
        "\n",
        "# to remove apex if installed previously, uncomment the following line\n",
        "# !pip uninstall apex           # remove apex if installed previously"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFtwyh-NnQ2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: https://zerowithdot.com/colab-github-workflow/\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive'     # default for the drive\n",
        "PROJ = 'My Drive/pessimism_research'    # path to your project on Drive\n",
        "\n",
        "PROJECT_PATH = join(ROOT, PROJ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQFevtrYoMJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this code block only when your session is terminated\n",
        "drive.mount(ROOT)           # mount the drive at /content/drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZFt6b_ulkV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: https://zerowithdot.com/colab-github-workflow/\n",
        "GIT_USERNAME = \"namrathaurs\"\n",
        "GIT_REPOSITORY = \"test-repo\"\n",
        "\n",
        "GIT_PATH = \"https://github.com/{}/{}.git\".format(GIT_USERNAME, GIT_REPOSITORY)\n",
        "!git clone \"{GIT_PATH}\" \"{PROJECT_PATH}\"\n",
        "# !rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIrtILbfk4iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git remote -v                  # view the remote repository details (aka origin)\n",
        "# !git pull origin master         # pull all updates from the 'origin'\n",
        "# !rm -rf /content/drive/My\\ Drive/pessimism_research         # in case you want to remove the existing cloned directory in your GDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D65KXtGZZ-lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (ONE TIME ONLY)\n",
        "# install required libraries/packages for running the notebook\n",
        "!pip install transformers\n",
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrBvjNcxA35o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "# used to test if cuda support is enabled\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PneU3onG3e97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # abspath resolves redundant separators and up-level references\n",
        "    data_dir = os.path.abspath(os.path.join(PROJECT_PATH, \"data/data_base\"))\n",
        "\n",
        "    # Read the data from files\n",
        "    train_df = pd.read_csv(os.path.join(data_dir, \"trn_A.csv\"))\n",
        "    valdn_df = pd.read_csv(os.path.join(data_dir, \"val_A.csv\"))\n",
        "    # test_df = pd.read_csv(os.path.join(data_dir, \"tst_A.csv\"))\n",
        "    print(train_df.shape, valdn_df.shape)\n",
        "\n",
        "    # change datatype of labels column from int to float to avoid runtime warning with respect to double_scalars (see Issue #2)\n",
        "    train_df = train_df.astype({\"labels_for_settingA\": np.float64})\n",
        "    valdn_df = valdn_df.astype({\"labels_for_settingA\": np.float64})\n",
        "\n",
        "    # initialize the pre-trained model (pretrained weights)\n",
        "    model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=True)\n",
        "    \n",
        "    # train the model (fine-tune the pre-trained model on the training data)\n",
        "    model.train_model(train_df)\n",
        "\n",
        "    tmp1 = valdn_df[valdn_df.loc[:, 'labels_for_settingA'] == 1.0]\n",
        "    print(\"Optimistic tweets in validation set: \", tmp1.shape)\n",
        "    tmp2 = valdn_df[valdn_df.loc[:, 'labels_for_settingA'] == 0.0]\n",
        "    print(\"Pessimistic tweets in validation set: \", tmp2.shape)\n",
        "\n",
        "    # use the predict method to make predictions and then use these predictions for evaluation\n",
        "    # predict method requires examples to be formatted as a list\n",
        "    valdn_samples = valdn_df['Tweet'].to_list()\n",
        "    valdn_true_lbls = valdn_df['labels_for_settingA'].to_list()\n",
        "\n",
        "    # test the trained model on the validation data\n",
        "    pred_labels, model_outputs = model.predict(valdn_samples)\n",
        "\n",
        "        # report the evaluation metrics\n",
        "    acc = metrics.accuracy_score(valdn_true_lbls, pred_labels)\n",
        "    f1 = metrics.f1_score(valdn_true_lbls, pred_labels)\n",
        "    cm = metrics.confusion_matrix(valdn_true_lbls, pred_labels)\n",
        "\n",
        "    print(\"Accuracy: %.3f\" % acc)\n",
        "    print(\"F1 score: %.3f\" % f1)\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYCLYSR43ib-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upon execution, script starts here!\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRCez8Z_8Jvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3 folders are created when a pre-trained model from the simpletransformers\n",
        "# package is used to train and predict. You get an error message that says outputs\n",
        "# directory exists when you re-run the notebook.\n",
        "# Either you can delete these folders that are created programmatically\n",
        "# Or you can edit the configuration settings to overwrite the directory contents\n",
        "!rm -rf cache_dir/ outputs/ runs/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}